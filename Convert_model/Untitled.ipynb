{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a04603d2-1ea7-486f-b914-cd68be3ff64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "\n",
    "model_name = \"resnet50\"   # ví dụ\n",
    "model = timm.create_model(\n",
    "    model_name,\n",
    "    pretrained=True,\n",
    "    num_classes=1000\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    \"model.onnx\",\n",
    "    opset_version=13,\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    do_constant_folding=True,\n",
    "    dynamic_axes=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a54e8272-750b-43f3-ab2d-1ec0f33b1df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CondaError: Run 'conda init' before 'conda activate'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "python3 -m onnxsim model.onnx model_sim.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca008b2-4aaa-464e-9c8a-2414d76ecf3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I rknn-toolkit2 version: 2.3.2\n",
      "I Loading : 100%|███████████████████████████████████████████████| 108/108 [00:00<00:00, 6927.12it/s]\n",
      "D base_optimize ...\n",
      "D base_optimize done.\n",
      "D \n",
      "D fold_constant ...\n",
      "D fold_constant done.\n",
      "D \n",
      "D correct_ops ...\n",
      "D correct_ops done.\n",
      "D \n",
      "D fuse_ops ...\n",
      "D fuse_ops results:\n",
      "D     convert_global_avgpool_to_conv: remove node = ['/global_pool/pool/GlobalAveragePool'], add node = ['/global_pool/pool/GlobalAveragePool_2conv0']\n",
      "D     convert_flatten_to_reshape: remove node = ['/global_pool/flatten/Flatten'], add node = ['/global_pool/flatten/Flatten_2rs']\n",
      "D     convert_gemm_by_exmatmul: remove node = ['/fc/Gemm'], add node = ['/global_pool/flatten/Flatten_output_0_tp', '/global_pool/flatten/Flatten_output_0_tp_rs', '/fc/Gemm#1', 'output_mm_tp', 'output_mm_tp_rs']\n",
      "D     unsqueeze_to_4d_transpose: remove node = [], add node = ['/global_pool/flatten/Flatten_output_0_rs', '/global_pool/flatten/Flatten_output_0_tp-rs']\n",
      "D     bypass_two_reshape: remove node = ['/global_pool/flatten/Flatten_output_0_rs', '/global_pool/flatten/Flatten_2rs']\n",
      "D     fuse_transpose_reshape: remove node = ['/global_pool/flatten/Flatten_output_0_tp', 'output_mm_tp']\n",
      "D     bypass_two_reshape: remove node = ['/global_pool/flatten/Flatten_output_0_tp_rs', '/global_pool/flatten/Flatten_output_0_tp-rs']\n",
      "D     convert_exmatmul_to_conv: remove node = ['/fc/Gemm#1'], add node = ['/fc/Gemm#2']\n",
      "D     fold_constant ...\n",
      "D     fold_constant done.\n",
      "D fuse_ops done.\n",
      "D \n",
      "D sparse_weight ...\n",
      "D sparse_weight done.\n",
      "D \n",
      "I GraphPreparing : 100%|███████████████████████████████████████| 122/122 [00:00<00:00, 32408.96it/s]\n",
      "I Quantizating 1/6: 100%|█████████████████████████████████████████| 122/122 [00:15<00:00,  7.75it/s]\n",
      "I Quantizating 2/6: 100%|█████████████████████████████████████████| 122/122 [00:15<00:00,  7.65it/s]\n",
      "I Quantizating 3/6: 100%|█████████████████████████████████████████| 122/122 [00:15<00:00,  7.73it/s]\n",
      "I Quantizating 4/6: 100%|█████████████████████████████████████████| 122/122 [00:15<00:00,  7.80it/s]\n",
      "I Quantizating 5/6:  72%|██████████████████████████████▎           | 88/122 [00:11<00:03, 10.92it/s]"
     ]
    }
   ],
   "source": [
    "from rknn.api import RKNN\n",
    "\n",
    "rknn = RKNN(verbose=True)\n",
    "\n",
    "rknn.config(\n",
    "    mean_values=[[123.675, 116.28, 103.53]],\n",
    "    std_values=[[58.395, 57.12, 57.375]],\n",
    "    target_platform=\"rk3588\",\n",
    "    quantized_dtype=\"w8a8\"\n",
    ")\n",
    "\n",
    "\n",
    "ret = rknn.load_onnx(model=\"model_sim.onnx\")\n",
    "assert ret == 0\n",
    "\n",
    "ret = rknn.build(\n",
    "    do_quantization=True,\n",
    "    dataset=\"dataset.txt\"\n",
    ")\n",
    "assert ret == 0\n",
    "\n",
    "rknn.export_rknn(\"model.rknn\")\n",
    "rknn.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24d804d-3d68-4cd5-9188-7678f8aa52f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rknn)",
   "language": "python",
   "name": "rknn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
